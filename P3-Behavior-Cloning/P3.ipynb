{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import pickle\n",
    "#import cv2\n",
    "import math\n",
    "import time\n",
    "import h5py\n",
    "import json\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "#import matplotlib.image as mpimg\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Lambda\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import theano\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('driving_log.csv')\n",
    "center = df[[0]]\n",
    "center = np.squeeze(center.values)\n",
    "left = df[[1]]\n",
    "left = np.squeeze(left.values)\n",
    "right = df[[2]]\n",
    "right = np.squeeze(right.values)\n",
    "steering = df[[3]]\n",
    "steering = np.squeeze(steering.values)\n",
    "\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_generator(Images,steering,training=0,batch_size=10,threshold=2):\n",
    "    ctr=0\n",
    "\n",
    "    while( (training and ctr<len(steering) ) or (not training) ) :\n",
    "    \n",
    "        if ((not training) and (ctr>=len(steering))):\n",
    "            ctr=0\n",
    "\n",
    "        data,labels=preprocess(Images[ctr:ctr+batch_size],steering[ctr:ctr+batch_size],threshold)    \n",
    "        ctr +=batch_size\n",
    "\n",
    "        yield data,labels\n",
    "        \n",
    "def crop(img):\n",
    "    new_size_col=120\n",
    "    new_size_row=60\n",
    "    #img=img[60:145,:,:]\n",
    "    img=cv2.resize(img,(new_size_col,new_size_row), interpolation=cv2.INTER_AREA)\n",
    "    return img\n",
    "        \n",
    "def preprocess(Images,steering,threshold):\n",
    "    row,col,ch=(mpimg.imread(Images[0][27:35] + '/' + Images[0][36:])).shape\n",
    "\n",
    "    img = []\n",
    "    steer = []\n",
    "        \n",
    "    for i,path in enumerate(Images):\n",
    "\n",
    "        I=mpimg.imread(path[27:35] + '/'+ path[36:])\n",
    "\n",
    "        #if(np.random.randint(2)):\n",
    "        #    I=augment_brightness_camera_images(I)\n",
    "\n",
    "            \n",
    "        img.append(crop(I))\n",
    "        steer.append(steering[i])\n",
    "\n",
    "        #if steering[i]<-threshold or steering[i]>threshold :\n",
    "        #    I=np.fliplr(I)\n",
    "        #    img.append(crop(I))\n",
    "        #    steer.append(-steering[i])\n",
    "\n",
    "    return np.asarray(img),np.asarray(steer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3222892 -0.2801272  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.       ]\n",
      "[-0.400292  -0.3177552  0.         0.         0.         0.        -0.2004898\n",
      "  0.         0.        -0.2859993]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(center, steering, test_size = 0.2, random_state = 0)\n",
    "train_data = data_generator(X_train, y_train)\n",
    "batch_x, batch_y = next(train_data)\n",
    "print(batch_y)\n",
    "batch_x, batch_y = next(train_data)\n",
    "print(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#reading in an image\\nlog = pd.read_csv('driving_log_Arun.csv')\\nX = []\\nprint(len(log))\\nfor n in range(len(log)):\\n    img = mpimg.imread(log.ix[n][0][:])#35] + '/' + log.ix[n][0][36:])\\n    img = cv2.resize(img,(120,60))\\n    #left = mpimg.imread(log.ix[n][1][28:36] + '/' + log.ix[n][1][37:])\\n    #right = mpimg.imread(log.ix[n][2][28:36] + '/' + log.ix[n][2][37:])\\n    #new = np.concatenate((np.concatenate((left,img), axis = 2), right), axis = 2)\\n    img = img/255 - 0.5\\n    X.append(img)\\nX = np.asarray(X)\\nplt.imshow(X[1])\\nprint(X.shape)\\nY = np.asarray(log.ix[:,3])\\nX_train, X_valid, y_train, y_valid = train_test_split(X, Y, test_size = 0.2, random_state = 0)\\nprint(X_train.shape)\\nprint(X_valid.shape)\\n#print(Y_val.shape)\\n\\nX_train,y_train = shuffle(X_train, y_train)\\n\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#reading in an image\n",
    "log = pd.read_csv('driving_log_Arun.csv')\n",
    "X = []\n",
    "print(len(log))\n",
    "for n in range(len(log)):\n",
    "    img = mpimg.imread(log.ix[n][0][:])#35] + '/' + log.ix[n][0][36:])\n",
    "    img = cv2.resize(img,(120,60))\n",
    "    #left = mpimg.imread(log.ix[n][1][28:36] + '/' + log.ix[n][1][37:])\n",
    "    #right = mpimg.imread(log.ix[n][2][28:36] + '/' + log.ix[n][2][37:])\n",
    "    #new = np.concatenate((np.concatenate((left,img), axis = 2), right), axis = 2)\n",
    "    img = img/255 - 0.5\n",
    "    X.append(img)\n",
    "X = np.asarray(X)\n",
    "plt.imshow(X[1])\n",
    "print(X.shape)\n",
    "Y = np.asarray(log.ix[:,3])\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "#print(Y_val.shape)\n",
    "\n",
    "X_train,y_train = shuffle(X_train, y_train)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Activation, Convolution2D, Flatten, MaxPooling2D, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(128, 3, 3, border_mode = 'valid', input_shape = (60, 120, 3)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(128, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1))\n",
    "#model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_37 (Convolution2D) (None, 58, 118, 128)  3584        convolution2d_input_13[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_49 (Activation)       (None, 58, 118, 128)  0           convolution2d_37[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_37 (MaxPooling2D)   (None, 29, 59, 128)   0           activation_49[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_38 (Convolution2D) (None, 27, 57, 32)    36896       maxpooling2d_37[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_50 (Activation)       (None, 27, 57, 32)    0           convolution2d_38[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_38 (MaxPooling2D)   (None, 13, 28, 32)    0           activation_50[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)             (None, 13, 28, 32)    0           maxpooling2d_38[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_39 (Convolution2D) (None, 11, 26, 128)   36992       dropout_37[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_51 (Activation)       (None, 11, 26, 128)   0           convolution2d_39[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_39 (MaxPooling2D)   (None, 5, 13, 128)    0           activation_51[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)             (None, 5, 13, 128)    0           maxpooling2d_39[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)             (None, 8320)          0           dropout_38[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_25 (Dense)                 (None, 1024)          8520704     flatten_13[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_52 (Activation)       (None, 1024)          0           dense_25[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)             (None, 1024)          0           activation_52[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_26 (Dense)                 (None, 1)             1025        dropout_39[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 8,599,201\n",
      "Trainable params: 8,599,201\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Epoch 1/15\n",
      "7s - loss: 22484.0792 - mean_squared_error: 22484.0792 - val_loss: 0.0385 - val_mean_squared_error: 0.0385\n",
      "Epoch 2/15\n",
      "5s - loss: 0.0407 - mean_squared_error: 0.0407 - val_loss: 0.0327 - val_mean_squared_error: 0.0327\n",
      "Epoch 3/15\n",
      "5s - loss: 0.0380 - mean_squared_error: 0.0380 - val_loss: 0.0323 - val_mean_squared_error: 0.0323\n",
      "Epoch 4/15\n",
      "5s - loss: 0.0354 - mean_squared_error: 0.0354 - val_loss: 0.0321 - val_mean_squared_error: 0.0321\n",
      "Epoch 5/15\n",
      "5s - loss: 0.0352 - mean_squared_error: 0.0352 - val_loss: 0.0319 - val_mean_squared_error: 0.0319\n",
      "Epoch 6/15\n",
      "5s - loss: 0.0360 - mean_squared_error: 0.0360 - val_loss: 0.0318 - val_mean_squared_error: 0.0318\n",
      "Epoch 7/15\n",
      "5s - loss: 0.0354 - mean_squared_error: 0.0354 - val_loss: 0.0316 - val_mean_squared_error: 0.0316\n",
      "Epoch 8/15\n",
      "5s - loss: 0.0358 - mean_squared_error: 0.0358 - val_loss: 0.0314 - val_mean_squared_error: 0.0314\n",
      "Epoch 9/15\n",
      "5s - loss: 0.0344 - mean_squared_error: 0.0344 - val_loss: 0.0312 - val_mean_squared_error: 0.0312\n",
      "Epoch 10/15\n",
      "5s - loss: 0.0344 - mean_squared_error: 0.0344 - val_loss: 0.0310 - val_mean_squared_error: 0.0310\n",
      "Epoch 11/15\n",
      "5s - loss: 0.0353 - mean_squared_error: 0.0353 - val_loss: 0.0308 - val_mean_squared_error: 0.0308\n",
      "Epoch 12/15\n",
      "5s - loss: 0.0338 - mean_squared_error: 0.0338 - val_loss: 0.0306 - val_mean_squared_error: 0.0306\n",
      "Epoch 13/15\n",
      "5s - loss: 0.0340 - mean_squared_error: 0.0340 - val_loss: 0.0304 - val_mean_squared_error: 0.0304\n",
      "Epoch 14/15\n",
      "5s - loss: 0.0334 - mean_squared_error: 0.0334 - val_loss: 0.0302 - val_mean_squared_error: 0.0302\n",
      "Epoch 15/15\n",
      "5s - loss: 0.0328 - mean_squared_error: 0.0328 - val_loss: 0.0300 - val_mean_squared_error: 0.0300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd435421128>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "'''\n",
    "model.compile(optimizer='rmsprop',\n",
    "          loss='binary_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "'''\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer=Adam(lr = 0.001),\n",
    "              metrics=['mean_squared_error'])\n",
    "\"\"\"\n",
    "history = model.fit(data_generator(X_train,y_train,training=0,batch_size=128),\n",
    "                    samples_per_epoch=len(y_train),\n",
    "                    validation_data=data_generator(X_test,y_test,training=0,batch_size=128),\n",
    "                    nb_val_samples=len(y_test), nb_epoch=10, verbose=1)\n",
    "\"\"\"\n",
    "model.fit_generator(data_generator(X_train,y_train,training=0,batch_size=64),\n",
    "                    samples_per_epoch=len(y_train),\n",
    "                    validation_data=data_generator(X_test,y_test,training=0,batch_size=64),\n",
    "                    nb_val_samples=len(y_test),                    \n",
    "                    nb_epoch=15,\n",
    "                    verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
